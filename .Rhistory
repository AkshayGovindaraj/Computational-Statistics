rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price + Location + MLS~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_rsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#### Lasso Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price + +Location + MLS~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_ssale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = 0,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price + Location + MLS~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_fsale <- cv.glmnet(x[train,], y[train], alpha = 1)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price + Location + MLS~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_rsale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = 0,  type = 'coefficients')
#Predictions
ridge.pred <- predict(ridge.mod, s = 0, newx = x[test,])
lasso.pred <- predict(lasso.mod, s = 0, newx = x[test,])
mse_ridge <- mean((ridge.pred-ytest)^2)
mse_lasso <- mean((lasso.pred-ytest)^2)
View(x)
#House prices - Variable Selection
library(glmnet)
houseprices = read.csv("RealEstate.csv")
#### Ridge Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_ssale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
predict(ridge.mod, s = 0,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_fsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_rsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#### Lasso Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_ssale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = 0,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_fsale <- cv.glmnet(x[train,], y[train], alpha = 1)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_rsale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = 0,  type = 'coefficients')
#Predictions
ridge.pred <- predict(ridge.mod, s = 0, newx = x[test,])
lasso.pred <- predict(lasso.mod, s = 0, newx = x[test,])
mse_ridge <- mean((ridge.pred-ytest)^2)
mse_lasso <- mean((lasso.pred-ytest)^2)
predict(ridge.mod, s = 0,  type = 'coefficients')
cv.out_ssale
cv.out_ssale$lambda
cv.out_ssale$lambda.min
predict(ridge.mod, s = cv.out_ssale_ridge$lambda.min,  type = 'coefficients')
cv.out_ssale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
predict(ridge.mod, s = cv.out_ssale_ridge$lambda.min,  type = 'coefficients')
#House prices - Variable Selection
library(glmnet)
houseprices = read.csv("RealEstate.csv")
#### Ridge Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_ssale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
predict(ridge.mod, s = cv.out_ssale_ridge$lambda.min,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_fsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_rsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#### Lasso Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_ssale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = cv.out_ssale$lambda.min,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_fsale <- cv.glmnet(x[train,], y[train], alpha = 1)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_rsale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = cv.out_rsale$lambda.min,  type = 'coefficients')
#Predictions
best_ridge =
ridge.pred <- predict(ridge.mod, s = 0, newx = x[test,])
lasso.pred <- predict(lasso.mod, s = 0, newx = x[test,])
mse_ridge <- mean((ridge.pred-ytest)^2)
mse_lasso <- mean((lasso.pred-ytest)^2)
ridge.pred <- predict(ridge.mod, s = cv.out_rsale_ridge$lambda.min, newx = x[test,])
lasso.pred <- predict(lasso.mod, s = cv.out_rsale$lambda.min, newx = x[test,])
mse_ridge <- mean((ridge.pred-ytest)^2)
mse_lasso <- mean((lasso.pred-ytest)^2)
mse_ridge
mse_lasso
lasso.pred <- predict(lasso.mod, s = 1000000000, newx = x[test,])
predict(lasso.mod, s = cv.out_rsale$lambda.min,  type = 'coefficients')
predict(lasso.mod, s = 1000000000,  type = 'coefficients')
predict(lasso.mod, s = 10000000,  type = 'coefficients')
predict(lasso.mod, s = 100000,  type = 'coefficients')
predict(lasso.mod, s = 500000,  type = 'coefficients')
predict(lasso.mod, s = 300000,  type = 'coefficients')
predict(lasso.mod2, s = 300000,  type = 'coefficients')
predict(lasso.mod3, s = 300000,  type = 'coefficients')
#House prices - Variable Selection
library(glmnet)
houseprices = read.csv("RealEstate.csv")
#### Ridge Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_ssale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
predict(ridge.mod, s = cv.out_ssale_ridge$lambda.min,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_fsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_rsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#### Lasso Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_ssale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = cv.out_ssale$lambda.min,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod2 <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_fsale <- cv.glmnet(x[train,], y[train], alpha = 1)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod3 <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_rsale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = cv.out_rsale$lambda.min,  type = 'coefficients')
#Predictions
ridge.pred <- predict(ridge.mod, s = cv.out_rsale_ridge$lambda.min, newx = x[test,])
lasso.pred <- predict(lasso.mod, s = 1000000000, newx = x[test,])
predict(lasso.mod, s = 300000,  type = 'coefficients')
predict(lasso.mod2, s = 300000,  type = 'coefficients')
predict(lasso.mod3, s = 300000,  type = 'coefficients')
mse_ridge <- mean((ridge.pred-ytest)^2)
mse_lasso <- mean((lasso.pred-ytest)^2)
predict(lasso.mod, s = 100000,  type = 'coefficients')
predict(lasso.mod2, s = 100000,  type = 'coefficients')
ridge.mod3 <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
#House prices - Variable Selection
library(glmnet)
houseprices = read.csv("RealEstate.csv")
#### Ridge Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_ssale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
predict(ridge.mod, s = cv.out_ssale_ridge$lambda.min,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod2 <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_fsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
ridge.mod3 <- glmnet(x[train,], y[train], alpha = 0, lambda = lambda)
cv.out_rsale_ridge <- cv.glmnet(x[train,], y[train], alpha = 0)
#### Lasso Regression
#Short Sale case
ssale <- houseprices[ which(houseprices$Status == 'Short Sale'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., ssale)[,-1]
y <- ssale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_ssale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = cv.out_ssale$lambda.min,  type = 'coefficients')
#Foreclosure case
fsale <- houseprices[ which(houseprices$Status == 'Foreclosure'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., fsale)[,-1]
y <- fsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod2 <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_fsale <- cv.glmnet(x[train,], y[train], alpha = 1)
#Regular case
rsale <- houseprices[ which(houseprices$Status == 'Regular'), ]
#Using GLM - for short sale
x <- model.matrix(Price ~., rsale)[,-1]
y <- rsale$Price
lambda <- 10^seq(10, -2, length = 100)
#Test train split
set.seed(100)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
ytest = y[test]
lasso.mod3 <- glmnet(x[train,], y[train], alpha = 1, lambda = lambda)
cv.out_rsale <- cv.glmnet(x[train,], y[train], alpha = 1)
predict(lasso.mod, s = cv.out_rsale$lambda.min,  type = 'coefficients')
#Predictions
ridge.pred <- predict(ridge.mod, s = cv.out_rsale_ridge$lambda.min, newx = x[test,])
lasso.pred <- predict(lasso.mod, s = 1000000000, newx = x[test,])
predict(ridge.mod, s = 100000,  type = 'coefficients')
predict(ridge.mod2, s = 100000,  type = 'coefficients')
predict(ridge.mod3, s = 300000,  type = 'coefficients')
predict(lasso.mod, s = 100000,  type = 'coefficients')
predict(lasso.mod2, s = 100000,  type = 'coefficients')
predict(lasso.mod3, s = 300000,  type = 'coefficients')
mse_ridge <- mean((ridge.pred-ytest)^2)
mse_lasso <- mean((lasso.pred-ytest)^2)
#Nonlinear regression with spline
copper = read.table('copper-new.txt')
#Linear model
linear_model <- lm(V1~V2, data=copper)
summary(linear_model)
#Nonlinear regression with spline function
plot(copper$V1, copper$V2)
plot(copper$V2, copper$V1)
plot(linear_model)
abline(lm(height ~ bodymass))
abline(lm(V1~V2, data=copper))
plot(copper$V2, copper$V1)
abline(lm(V1~V2, data=copper))
#Nonlinear regression with spline function
fit<-lm(V1 ~ bs(V2,knots = c(100,200,450)),data = copper )
install.packages('splines')
library(splines)
#Nonlinear regression with spline function
fit<-lm(V1 ~ bs(V2,knots = c(100,200,450)),data = copper )
plot(copper$V2, copper$V1)
abline(lm(V1 ~ bs(V2,knots = c(100,200,450)),data = copper ))
plot(fit)
plot(fit)
#Plotting the Regression Line to the scatterplot
plot(V2,V1,col="grey",xlab="Temperature",ylab="Y",data=copper)
#Plotting the Regression Line to the scatterplot
plot(copper$V2,copper$V1,col="grey",xlab="Temperature",ylab="Y")
#Plotting the Regression Line to the scatterplot
agelims<-range(copper$V2)
age.grid<-seq(from=agelims[1], to = agelims[2])
agelims
points(age.grid,predict(fit,newdata = list(V2=age.grid)),col="darkgreen",lwd=2,type="l")
#adding cutpoints
abline(v=c(25,40,60),lty=2,col="darkgreen")
#Nonlinear regression with spline
copper = read.table('copper-new.txt')
#Linear model
linear_model <- lm(V1~V2, data=copper)
summary(linear_model)
#Nonlinear regression with spline function
fit<-lm(V1 ~ bs(V2,knots = c(100,200,450)),data = copper )
summary(fit)
plot(copper$V2, copper$V1)
#Plotting the Regression Line to the scatterplot
agelims<-range(copper$V2)
age.grid<-seq(from=agelims[1], to = agelims[2])
plot(copper$V2,copper$V1,col="grey",xlab="Temperature",ylab="Y")
points(age.grid,predict(fit,newdata = list(V2=age.grid)),col="darkgreen",lwd=2,type="l")
#adding cutpoints
abline(v=c(100,200,450),lty=2,col="darkgreen")
predict(fit, newdata = 400)
predict(fit, newdata = list(V2=400))
predict(linear_model, newdata = list(V2=400))
